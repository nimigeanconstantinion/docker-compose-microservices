
networks:
  mynet:
    driver: bridge

volumes:
  db_data:
  kibana_data: # Definirea volumului
  es_data:
  logstash_pipeline:
  prometheus_data:
  grafana_data:
  grafana_provisioning:
    driver: local
  rabbitmq_data:
  rabbitmq_log:

x-variables:
  elastic_password: &elastic_password 'passwOrd'
  kibana_password: &kibana_password 'passwOrd'

services:
  discovery-service:
    image: ion21/newdiscovery:01.07.2024.14.39.29
    networks:
      - mynet
    ports:
      - "8761:8761"
    environment:
      SPRING_ZIPKIN_BASE_URL: http://zipkin:9411

  mysql:
    image: mysql:5.7
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: micro_db
    networks:
      - mynet
    ports:
      - "3307:3306"
    volumes:
      - db_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 1

  query-service:
    image: ion21/query-service:15.10.2024.08.53.35
    networks:
      - mynet
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_ZIPKIN_BASE_URL: http://zipkin:9411
    ports:
      - "8082:8082"
    depends_on:
      discovery-service:
        condition: service_started
      zipkin:
        condition: service_started

  command-service:
    image: ion21/command-service:16.11.2024.16.22.33
    networks:
      - mynet
    ports:
      - "8081:8081"
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_ZIPKIN_BASE_URL: http://zipkin:9411
    depends_on:
      mysql:
        condition: service_healthy
      discovery-service:
        condition: service_started
      zipkin:
        condition: service_started

  nserver-service:
    image: ion21/server-service:23.10.2024.16.12.17
    networks:
      - mynet
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_ZIPKIN_BASE_URL: http://zipkin:9411
      ADDITIONAL_CORS_ORIGIN: "http://localhost:5000,http://localhost:3000,http://63.32.92.152:3000,http://63.32.92.152:5000"
    depends_on:
      mysql:
        condition: service_healthy
      discovery-service:
        condition: service_started
      zipkin:
        condition: service_started

  edge:
    image: ion21/gateway-service:15.10.2024.08.54.44
    networks:
      - mynet
    ports:
      - "5000:5000"
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_ZIPKIN_BASE_URL: http://zipkin:9411
    depends_on:
      discovery-service:
        condition: service_started
      nserver-service:
        condition: service_started
      zipkin:
        condition: service_started

  client:
    image: ion21/client-service:02.10.2024.11.59.05
    networks:
      - mynet
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - REACT_APP_PATH_TO=development
#      - REACT_APP_API_URL=http://63.32.92.152:5000
      - REACT_APP_API_URL=http://localhost:5000

    depends_on:
      - edge

  rabbitmq:
    image: rabbitmq:3.9.11-management-alpine
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    networks:
      - mynet

    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - rabbitmq_log:/var/log/rabbitmq
    restart: always
    
  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    networks:
      - mynet
    ports:
      - "9411:9411"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9411/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    container_name: elasticsearch
    environment:
      ELASTIC_PASSWORD: *elastic_password
      discovery.type: 'single-node'
      cluster.name: 'elasticsearch'
      bootstrap.memory_lock: 'true'
      ES_JAVA_OPTS: '-Xms1g -Xmx1g'
      xpack.security.enabled: 'true'
      xpack.security.http.ssl.enabled: 'false'
    networks:
      - mynet
    ports:
      - "9200:9200"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - es_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.1
    container_name: kibana
    environment:
      ELASTICSEARCH_HOSTS: 'http://elasticsearch:9200'
      ELASTICSEARCH_USERNAME: 'kibana_system'
      ELASTICSEARCH_PASSWORD: *kibana_password
      TELEMETRY_ENABLED: 'false'
      bootstrap.memory_lock: 'true'

    networks:
      - mynet
    ports:
      - '5601:5601'
    depends_on:
      - elasticsearch
    volumes:
      - kibana_data:/usr/share/kibana/data # MonteazÄƒ volumul pentru datele Kibana

#  logstash:
#    image: docker.elastic.co/logstash/logstash:8.12.1
#    container_name: logstash
#    environment:
#      ELASTIC_PASSWORD: *elastic_password
#      bootstrap.memory_lock: 'true'
#      CONFIG_STRING: |
#        input {
#          tcp {
#            port => 3100
#            codec => json_lines
#          }
#        }
#        output {
#          elasticsearch {
#            hosts => ["http://elasticsearch:9200"]
#            user => "elastic"
#            password => "$${ELASTIC_PASSWORD}"
#            ssl => false
#          }
#        }
#    networks:
#      - mynet
#    ports:
#      - "3100:3100"
#    depends_on:
#      - elasticsearch

  logstash:
    image: docker.elastic.co/logstash/logstash:8.12.1
    container_name: logstash
    environment:
      ELASTIC_PASSWORD: *elastic_password
      bootstrap.memory_lock: 'true'
      CONFIG_STRING: |
        input {
          tcp {
            port => 3100
            codec => json_lines
          }
        }
        filter {
          grok {
            match => {
              "message" => "cmdUpd: Optional\\[id:%{NUMBER:commUpd.id};articol:%{DATA:commUpd.articol};id_furniz:%{NUMBER:commUpd.id_furniz};furnizor:%{DATA:commUpd.furnizor};nr_zile:%{NUMBER:commUpd.nr_zile}\\]\\."
            }
          }
        }
        output {
          elasticsearch {
            hosts => ["http://elasticsearch:9200"]
            user => "elastic"
            password => "$${ELASTIC_PASSWORD}"
            ssl => false
          }
        }
    networks:
      - mynet
    ports:
      - "3100:3100"
    depends_on:
      - elasticsearch

  setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    container_name: setup
    environment:
      ELASTIC_PASSWORD: *elastic_password
      KIBANA_PASSWORD: *kibana_password
      bootstrap.memory_lock: 'true'

#    command:
#      - bash
#      - -c
#      - |
#        echo "Waiting for Elasticsearch availability";
#        until curl -s http://elasticsearch:9200 | grep -q "missing authentication credentials"; do sleep 10; done;
#        echo "Setting kibana_system password";
#        until curl -s -X POST -u "elastic:$${ELASTIC_PASSWORD}" -H "Content-Type: application/json" \
#          http://elasticsearch:9200/_security/user/kibana_system/_password \
#          -d "{\"password\":\"$${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
#        echo "All done!";
    command:
      - bash
      - -c
      - |
        echo "Waiting for Elasticsearch availability";
        until curl -s http://elasticsearch:9200 | grep -q "missing authentication credentials"; do sleep 10; done;
        echo "Setting kibana_system password";
        until curl -s -X POST -u "elastic:$${ELASTIC_PASSWORD}" -H "Content-Type: application/json" \
          http://elasticsearch:9200/_security/user/kibana_system/_password \
          -d "{\"password\":\"$${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "Creating index template for logstash-*";
        curl -s -X PUT -u "elastic:$${ELASTIC_PASSWORD}" -H "Content-Type: application/json" \
          http://elasticsearch:9200/_template/logstash_template \
          -d '{
            "index_patterns": ["logstash-*"],
            "mappings": {
              "properties": {
                "message": {
                  "type": "text",
                  "fields": {
                    "keyword": {
                      "type": "keyword",
                      "ignore_above": 256
                    }
                  }
                },
                "commUpd.id": {
                  "type": "integer"
                },
                "commUpd.articol": {
                  "type": "text"
                },
                "commUpd.id_furniz": {
                  "type": "integer"
                },
                "commUpd.furnizor": {
                  "type": "text"
                },
                "commUpd.nr_zile": {
                  "type": "integer"
                }
              }
            }
          }';
        echo "All done!";
    networks:
      - mynet

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - prometheus_data:/prometheus
    environment:
      PROMETHEUS_CONFIG: |
        global:
          scrape_interval: 15s
        scrape_configs:
          - job_name: 'spring-boot-apps'
            metrics_path: '/actuator/prometheus'
            scrape_interval: 5s
            static_configs:
              - targets:
                  - 'command-service:8081'
                  - 'query-service:8082'
                  - 'nserver-service:8080'
                  - 'edge:5000'
    entrypoint:
      - /bin/sh
      - -c
      - |
        echo "$${PROMETHEUS_CONFIG}" > /etc/prometheus/prometheus.yml
        /bin/prometheus --config.file=/etc/prometheus/prometheus.yml
    ports:
      - '9090:9090'
    depends_on:
      - edge
    networks:
      - mynet

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3200:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=secret
    depends_on:
      - prometheus
    networks:
      - mynet
    volumes:
      - grafana_data:/var/lib/grafana
      - grafana_provisioning:/etc/grafana/provisioning
    entrypoint:
      - /bin/sh
      - -c
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        mkdir -p /etc/grafana/provisioning/dashboards
        echo '
        apiVersion: 1

        datasources:
          - name: Prometheus
            type: prometheus
            access: proxy
            isDefault: true
            url: http://prometheus:9090
            version: 1
            editable: false
        ' > /etc/grafana/provisioning/datasources/datasource.yml
        /run.sh
